{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy,csv,time\n",
    "\n",
    "ACCESS_TOKEN = '938493239853813762-tlImlRTGU6RraqmBQQQQ3K5klFmHwvG'\n",
    "ACCESS_SECRET = 'Ga79wDf0YK9YtYc21XEfBH10L0wAttnDL5wQXVT7oNj1J'\n",
    "CONSUMER_KEY = 'zHK9haWtcpGWHUq12fEMn3Fyw'\n",
    "CONSUMER_SECRET = 'jIZj1D7jPfXPGSIQTTEGMPgXhIR7lEqyBXRUnudcgpvPDc2wzm'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN,ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tool to delete unicode codes\n",
    "def unicodetoascii(text):\n",
    "    TEXT = (text.\n",
    "    \t\treplace('\\\\xe2\\\\x80\\\\x99', \"'\").\n",
    "            replace('\\\\xc3\\\\xa9', 'e').\n",
    "            replace('\\\\xe2\\\\x80\\\\x90', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x91', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x92', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x93', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x94', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x94', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x98', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\x9b', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\x9c', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9c', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9d', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9e', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9f', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\xa6', '...').#\n",
    "            replace('\\\\xe2\\\\x80\\\\xb2', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb3', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb4', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb5', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb6', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb7', \"'\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xba', \"+\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbb', \"-\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbc', \"=\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbd', \"(\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbe', \")\")\n",
    "                 )\n",
    "    return TEXT\n",
    "\n",
    "#Reading CSV file\n",
    "dataset=pd.read_csv('tweets3.csv', sep=',',quotechar='\"',header=None,)\n",
    "#Replacing Unicode characters\n",
    "dataset[2]=dataset[2].apply(unicodetoascii)\n",
    "#Deleting Urls\n",
    "delete_urls = lambda x:re.sub(r'http\\S+', '', x)\n",
    "dataset[2] = dataset[2].apply(delete_urls)\n",
    "#Deleting \"\n",
    "delete_quotes = lambda x:re.sub(r'\"', '', x)\n",
    "dataset[2] = dataset[2].apply(delete_quotes)\n",
    "#Deleting b\n",
    "delete_b = lambda x:re.sub(r'b\\'', '', x)\n",
    "dataset[2] = dataset[2].apply(delete_b)\n",
    "\n",
    "#Text cleaning\n",
    "def clean (X):\n",
    "    X=delete_urls(X)\n",
    "    X=delete_quotes(X)\n",
    "    X=delete_b(X)\n",
    "    return X\n",
    "#Datasets\n",
    "X=dataset[2].values\n",
    "Y=dataset[3].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data split\n",
    "x_train, x_test ,y_train,y_test = train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825393661550728"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine Learning NB\n",
    "text_clf_NB = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "text_clf_NB = text_clf_NB.fit(x_train, y_train)\n",
    "\n",
    "# Performance\n",
    "y_predicted = text_clf_NB.predict(x_test)\n",
    "np.mean(y_predicted == y_test)\n",
    "# 78% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loko/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72055012955949771"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine Learning SVM\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42)), ])\n",
    "\n",
    "_ = text_clf_svm.fit(x_train,y_train)\n",
    "predicted_svm = text_clf_svm.predict(x_test)\n",
    "np.mean(predicted_svm == y_test)\n",
    "# 71% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786126180001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search NB\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3)}\n",
    "gs_clf = GridSearchCV(text_clf_NB, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(x_train,y_train)\n",
    "print(gs_clf.best_score_)\n",
    "gs_clf.best_params_\n",
    "#78% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719405407714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(x_train,y_train)\n",
    "print(gs_clf_svm.best_score_)\n",
    "gs_clf_svm.best_params_\n",
    "#71% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tweet is recognized as democrat with a 78.28 % certainty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input : text + pipeline(fitted) , output : prediction + accuracy (works only with NB classifier)\n",
    "def tweet_prediction (txt,func):\n",
    "    iter = np.array([txt])\n",
    "    if (func.predict(iter)[0] == 1):\n",
    "        print(\"This tweet is recognized as democrat with a \"+str(round(func.predict_proba(iter)[0][1]*100,2))+\" % certainty\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"This tweet is recognized as republican with a \"+str(round(func.predict_proba(iter)[0][0]*100,2))+\" % certainty\")\n",
    "        return -1\n",
    "    \n",
    "tweet_prediction(\"Trump\",text_clf_NB)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The account @RepMiaLove is recognized as a republican account.\n"
     ]
    }
   ],
   "source": [
    "# Input : tweeter account + pipeline (fitted), output : prediction \n",
    "api = tweepy.API(auth)\n",
    "def account_prediction (acc,func):\n",
    "    iter=np.array([])\n",
    "    tweets = api.user_timeline(acc,count=10000)\n",
    "    time.sleep(0.1)\n",
    "    for tweet in tweets:\n",
    "        if ('RT @' not in tweet.text):\n",
    "            iter=np.append([clean(tweet.text)],iter)\n",
    "            \n",
    "    result = func.predict(iter)\n",
    "    ratio = np.mean(result)\n",
    "    #print (ratio)\n",
    "    if ratio <0 :\n",
    "        print(\"The account @\"+acc+\" is recognized as a republican account.\")\n",
    "    else:\n",
    "        print(\"The account @\"+acc+\" is recognized as a democrat account.\")\n",
    "        \n",
    "account_prediction(\"RepMiaLove\",text_clf_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
