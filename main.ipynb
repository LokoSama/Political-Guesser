{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy,csv,time\n",
    "\n",
    "ACCESS_TOKEN = '938493239853813762-tlImlRTGU6RraqmBQQQQ3K5klFmHwvG'\n",
    "ACCESS_SECRET = 'Ga79wDf0YK9YtYc21XEfBH10L0wAttnDL5wQXVT7oNj1J'\n",
    "CONSUMER_KEY = 'zHK9haWtcpGWHUq12fEMn3Fyw'\n",
    "CONSUMER_SECRET = 'jIZj1D7jPfXPGSIQTTEGMPgXhIR7lEqyBXRUnudcgpvPDc2wzm'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN,ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tool to delete unicode codes\n",
    "def unicodetoascii(text):\n",
    "    TEXT = (text.\n",
    "    \t\treplace('\\\\xe2\\\\x80\\\\x99', \"'\").\n",
    "            replace('\\\\xc3\\\\xa9', 'e').\n",
    "            replace('\\\\xe2\\\\x80\\\\x90', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x91', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x92', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x93', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x94', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x94', '-').\n",
    "            replace('\\\\xe2\\\\x80\\\\x98', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\x9b', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\x9c', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9c', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9d', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9e', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\x9f', '\"').\n",
    "            replace('\\\\xe2\\\\x80\\\\xa6', '...').#\n",
    "            replace('\\\\xe2\\\\x80\\\\xb2', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb3', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb4', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb5', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb6', \"'\").\n",
    "            replace('\\\\xe2\\\\x80\\\\xb7', \"'\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xba', \"+\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbb', \"-\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbc', \"=\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbd', \"(\").\n",
    "            replace('\\\\xe2\\\\x81\\\\xbe', \")\")\n",
    "                 )\n",
    "    return TEXT\n",
    "\n",
    "#Reading CSV file\n",
    "dataset=pd.read_csv('tweets3.csv', sep=',',quotechar='\"',header=None,)\n",
    "#Replacing Unicode characters\n",
    "dataset[2]=dataset[2].apply(unicodetoascii)\n",
    "#Deleting Urls\n",
    "delete_urls = lambda x:re.sub(r'http\\S+', '', x)\n",
    "dataset[2] = dataset[2].apply(delete_urls)\n",
    "#Deleting \"\n",
    "delete_quotes = lambda x:re.sub(r'\"', '', x)\n",
    "dataset[2] = dataset[2].apply(delete_quotes)\n",
    "#Deleting b\n",
    "delete_b = lambda x:re.sub(r'b\\'', '', x)\n",
    "dataset[2] = dataset[2].apply(delete_b)\n",
    "\n",
    "#Text cleaning\n",
    "def clean (X):\n",
    "    X=delete_urls(X)\n",
    "    X=delete_quotes(X)\n",
    "    X=delete_b(X)\n",
    "    return X\n",
    "#Datasets\n",
    "X=dataset[2].values\n",
    "Y=dataset[3].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data split\n",
    "x_train, x_test ,y_train,y_test = train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.800179390074%\n"
     ]
    }
   ],
   "source": [
    "#Machine Learning NB\n",
    "text_clf_nb = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "\n",
    "#Grid search NB\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3)}\n",
    "gs_clf = GridSearchCV(text_clf_nb, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(x_train,y_train)\n",
    "\n",
    "#Fitting with best hyperparameters\n",
    "text_clf_nb = gs_clf.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# Performance\n",
    "y_predicted = text_clf_nb.predict(x_test)\n",
    "print(\"Accuracy :\" + str(np.mean(y_predicted == y_test))+\"%\")\n",
    "# 80 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.739685070759%\n"
     ]
    }
   ],
   "source": [
    "#Machine Learning SVM\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf-svm', LinearSVC()) ])\n",
    "#Grid search SVM\n",
    "powers=np.array([2**-15,2**-13,2**-11,2**-9,2**-7])\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf-svm__C': powers}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(x_train,y_train)\n",
    "\n",
    "#Fitting with best hyperparameters\n",
    "text_clf_svm = gs_clf_svm.best_estimator_.fit(x_train,y_train)\n",
    "\n",
    "# Performance\n",
    "predicted_svm = text_clf_svm.predict(x_test)\n",
    "print(\"Accuracy :\"+ str(np.mean(predicted_svm == y_test))+\"%\")\n",
    "# 73,9 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tweet is recognized as democrat with a 79.99 % certainty\n",
      "This tweet is recognized as democrat.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifiers = text_clf_svm or text_clf_nb\n",
    "\n",
    "# Input : text + pipeline(fitted) , output : prediction + accuracy (works only with NB classifier)\n",
    "def tweet_prediction (txt,func):\n",
    "    iter = np.array([txt])\n",
    "    if (func==text_clf_nb):\n",
    "        if (func.predict(iter)[0] == 1):\n",
    "            print(\"This tweet is recognized as democrat with a \"+str(round(func.predict_proba(iter)[0][1]*100,2))+\" % certainty\")\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"This tweet is recognized as republican with a \"+str(round(func.predict_proba(iter)[0][0]*100,2))+\" % certainty\")\n",
    "            return -1\n",
    "    else:\n",
    "        if (func.predict(iter)[0] == 1):\n",
    "            print(\"This tweet is recognized as democrat.\")\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"This tweet is recognized as republican.\")\n",
    "            return -1\n",
    "    \n",
    "tweet_prediction(\"Trump\",text_clf_nb)\n",
    "tweet_prediction(\"Trump\",text_clf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The account @RepMiaLove is recognized as a republican account.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifiers = text_clf_svm or text_clf_nb\n",
    "\n",
    "# Input : tweeter account + pipeline (fitted), output : prediction \n",
    "api = tweepy.API(auth)\n",
    "def account_prediction (acc,func,verbose=None,count=None):\n",
    "    iter=np.array([])\n",
    "    if (count==None):\n",
    "        count=10000\n",
    "    tweets = api.user_timeline(acc,count=count)\n",
    "    for tweet in tweets:\n",
    "        if ('RT @' not in tweet.text):\n",
    "            iter=np.append([clean(tweet.text)],iter)\n",
    "            \n",
    "    result = func.predict(iter)\n",
    "    ratio = np.mean(result)\n",
    "    #print (ratio)\n",
    "    if ratio <0 :\n",
    "        if (verbose==None):\n",
    "            print(\"The account @\"+acc+\" is recognized as a republican account.\")\n",
    "        return -1\n",
    "    else:\n",
    "        if (verbose==None):\n",
    "            print(\"The account @\"+acc+\" is recognized as a democrat account.\")\n",
    "        return 1\n",
    "account_prediction(\"RepMiaLove\",text_clf_nb)\n",
    "#account_prediction(\"RepMiaLove\",text_clf_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : NB\n",
      "--- 215.87572479248047 seconds ---\n",
      "Accuracy :0.99\n",
      "Classifier : SVM\n",
      "--- 198.85703444480896 seconds ---\n",
      "Accuracy :0.87\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on accounts of US representatives \n",
    "#For reason of computing time, we only test accuracy for 100 accounts based on 50 last tweets \n",
    "def account_accuracy (classifier):\n",
    "    start_time = time.time()\n",
    "    acc_number=50\n",
    "    last_tweets=50\n",
    "    y=np.array([])\n",
    "    predicted=np.array([])\n",
    "    for member in tweepy.Cursor(api.list_members, 'thedemocrats', 'house-democrats').items(acc_number):\n",
    "        y=np.append(y,[1])\n",
    "        predicted=np.append(predicted,account_prediction(member.screen_name,classifier,False,last_tweets))\n",
    "    for member in tweepy.Cursor(api.list_members, 'housegop', 'house-republicans').items(acc_number):\n",
    "        y=np.append(y,[-1])\n",
    "        predicted=np.append(predicted,account_prediction(member.screen_name,classifier,False,last_tweets))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Accuracy :\" + str(np.mean(predicted==y)))\n",
    "\n",
    "print(\"Classifier : NB\")\n",
    "account_accuracy(text_clf_nb)\n",
    "print(\"Classifier : SVM\")\n",
    "account_accuracy(text_clf_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
